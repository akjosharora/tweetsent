Cleaning the text
  To improve the accuracy of predictions, we must have a good numerical representation of the text or tweets in our case, several
  Cleaning the text can add from 1 to 2% to overall accuracy for any classifier.
  step are taken in order to achieve that:
    - Converting the text to lower case.
    - Replace words preceded by not, no or words ending with "n't: (don't, mustn't, won't ...) with their opposite using an endligh dictionary.
    - Removing unwanted text:
      The following will be removed using regular expressions:
        - User names.
        - URLs.
        - Tags.
        - Empty tweets(Twitter API returns the string "Not Available" if the tweet doesn't contain a text).
        - Numbers.
        - Special characters.
    - Tokenization:
      The text will be tokenized into words.
    - Stop words removal:
      All stop words must be removed with the exception of no and not, these two were actually removed in step 2.
    - Stemming:
      All collected tokens or words are reduced to their stem, stemming does not always return a correct word, but it always reduced derived words to a single origin.
    -
